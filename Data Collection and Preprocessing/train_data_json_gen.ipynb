{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f42aed1",
   "metadata": {},
   "source": [
    "#### Train and Test split including Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae37ae-8683-4a98-bd51-313b6a3d844d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "INPUT_JSON = \"radgraph_processed.json\"\n",
    "OUTPUT_JSON = \"slava_llava_split_\"\n",
    "TEST_SPLIT = 0.05# 5% test split\n",
    "\n",
    "IMAGE_TOKEN = \"<image>\"\n",
    "\n",
    "\n",
    "recognition_prompts = [\n",
    "    \"Enumerate all abnormal radiographic findings seen on the frontal and lateral chest X-rays, along with their precise anatomical locations.\",\n",
    "    \"List every visible pathology in the lungs, heart, pleura, and bones, as observed on both frontal and lateral views.\",\n",
    "    \"Describe only the radiographic abnormalities visible in these dual-view chest X-rays. Exclude normal structures.\",\n",
    "    \"Identify and localize any abnormal opacities, effusions, consolidations, or structural deviations present in the chest radiographs.\",\n",
    "    \"Specify all observed abnormalities in the dual chest views, including their type (e.g., mass, effusion, opacity) and anatomical location.\",\n",
    "    \"Report abnormal findings only from the provided frontal and lateral chest X-ray images. Do not describe normal appearances.\",\n",
    "    \"What pathological signs can be identified across both X-ray views? Be specific about laterality and anatomical regions.\",\n",
    "    \"Describe all clinically relevant radiographic findings, focusing on abnormalities in the lungs, mediastinum, and chest wall.\",\n",
    "    \"From the dual-view chest radiographs, list any deviations from normal radiographic anatomy or pathology that requires clinical attention.\",\n",
    "    \"Summarize all abnormal chest X-ray findings, organized by anatomical region (e.g., lungs, heart, pleura, bones).\"\n",
    "]\n",
    "\n",
    "\n",
    "reasoning_prompts = [\n",
    "    \"Based on the findings in the frontal and lateral chest X-rays, what is the most likely clinical diagnosis?\",\n",
    "    \"Interpret the radiographic abnormalities observed in both views and explain their clinical implications.\",\n",
    "    \"Given the dual-view chest radiographs, what is your diagnostic impression and reasoning behind it?\",\n",
    "    \"Using the observed abnormalities in these X-rays, infer the likely pathology and explain its clinical relevance.\",\n",
    "    \"What clinical condition best explains the abnormal findings visible in these frontal and lateral chest radiographs?\"\n",
    "]\n",
    "def impression_starts_with_normal_phrases(impression):\n",
    "    impression_text = impression.strip() if impression else ''\n",
    "    starts_with_patterns = [\n",
    "        r\"^no\\b\",\n",
    "        r\"^no evidence\\b\",\n",
    "        r\"^no acute\\b\",\n",
    "        r\"^normal\\b\"\n",
    "    ]\n",
    "\n",
    "    for pattern in starts_with_patterns:\n",
    "        if re.match(pattern, impression_text, re.IGNORECASE):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "def infer_view_hint(findings_text):\n",
    "    text_upper = findings_text.upper()\n",
    "    if \"PA\" in text_upper and \"AP\" in text_upper:\n",
    "        return \"PA and AP chest X-ray views are shown.\"\n",
    "    elif \"PA\" in text_upper:\n",
    "        return \"PA and lateral chest X-ray views are shown.\"\n",
    "    elif \"AP\" in text_upper:\n",
    "        return \"AP and lateral chest X-ray views are shown.\"\n",
    "    else:\n",
    "        return \"Frontal and lateral chest X-ray views are shown.\"\n",
    "\n",
    "# Load RadGraph-processed JSON\n",
    "with open(INPUT_JSON, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "output = []\n",
    "normalcount=0\n",
    "abnormalCount = 0\n",
    "for study_id, entry in data.items():\n",
    "    findings = entry.get(\"findings\", \"\").strip()\n",
    "    impression = entry.get(\"impression\", \"\").strip()\n",
    "    image_paths = entry.get(\"image_paths\", [])\n",
    "    frontal = entry.get(\"image_paths\", \"\")\n",
    "    lateral= entry.get(\"image_paths\", \"\")\n",
    "    if not findings or not impression:\n",
    "        continue\n",
    "    if len(image_paths) < 2:\n",
    "        continue  # Need both frontal and lateral views\n",
    "\n",
    "    # Dynamic view hint based on findings\n",
    "    view_hint = infer_view_hint(findings)\n",
    "\n",
    "    # Build prompts with image tokens and helpful context\n",
    "    recognition_prompt = f\"{IMAGE_TOKEN}{view_hint} {random.choice(recognition_prompts)}\"\n",
    "    reasoning_prompt = f\"{IMAGE_TOKEN}{view_hint} {random.choice(reasoning_prompts)}\"\n",
    "    item = {\n",
    "        \"frontal\": frontal[0],\n",
    "        \"lateral\": lateral[1],\n",
    "        \"recognition_input\": recognition_prompt,\n",
    "        \"reasoning_input\": reasoning_prompt,\n",
    "        \"findings\": findings,\n",
    "        \"impression\": impression\n",
    "    }\n",
    "    output.append(item)\n",
    "    \n",
    "    # if impression_starts_with_normal_phrases(impression) and normalcount<100:\n",
    "    #     output.append(item)\n",
    "    #     normalcount+=1\n",
    "    # elif not impression_starts_with_normal_phrases(impression):\n",
    "    #     abnormalCount+=1\n",
    "    #     output.append(item)  \n",
    "\n",
    "# Shuffle and split into train/test\n",
    "random.shuffle(output)\n",
    "split_index = int(len(output) * (1 - TEST_SPLIT))\n",
    "train_data = output[:split_index]\n",
    "test_data = output[split_index:]\n",
    "\n",
    "\n",
    "with open(OUTPUT_JSON + 'train.json', \"w\") as f:\n",
    "    json.dump(train_data, f, indent=2)\n",
    "\n",
    "with open(OUTPUT_JSON + 'test.json', \"w\") as f:\n",
    "    json.dump(test_data, f, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Saved {len(train_data)} train, {len(test_data)} test\")\n",
    "print(f\"   '{OUTPUT_JSON}train.json'\")\n",
    "print(f\"   '{OUTPUT_JSON}test.json'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940e6fc",
   "metadata": {},
   "source": [
    "#### Generate Train Json For Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df584a2b-ff19-4e43-88b9-ae2441211005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_json = \"slava_llava_split_train.json\"  \n",
    "output_json = \"slava_llava_recognition.json\" \n",
    "\n",
    "with open(input_json, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "converted = []\n",
    "\n",
    "for item in data:\n",
    "        try:\n",
    "            frontal = item[\"frontal\"]\n",
    "            lateral = item[\"lateral\"]\n",
    "            instruction = item[\"recognition_input\"]\n",
    "            response = item[\"findings\"]\n",
    "    \n",
    "           \n",
    "            if not response.strip():\n",
    "                continue\n",
    "    \n",
    "            sample = {\n",
    "                \"frontal\": frontal,\n",
    "                \"lateral\":lateral,\n",
    "                \"conversations\": [\n",
    "                    {\"from\": \"human\", \"value\": instruction},\n",
    "                    {\"from\": \"gpt\", \"value\": response}\n",
    "                ]\n",
    "            }\n",
    "    \n",
    "            converted.append(sample)\n",
    "           \n",
    "    \n",
    "        except KeyError as e:\n",
    "            print(f\"[Skip] Missing key {e} in item\")\n",
    "\n",
    "        \n",
    "\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump(converted, f, indent=2)\n",
    "\n",
    "print(f\"Converted {len(converted)} samples to {output_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecda51d",
   "metadata": {},
   "source": [
    "#### Generate Train Json For Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c79f4b-c146-4373-9b41-5473dcd3bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "input_json = \"slava_llava_split_train.json\"\n",
    "output_json = \"slava_llava_reasoning.json\"\n",
    "\n",
    "\n",
    "with open(input_json, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sample_buckets = defaultdict(list)\n",
    "for item in data:\n",
    "    impression = item.get(\"impression\", \"\").lower()\n",
    "    is_normal = \"no acute\" in impression or \"normal\" in impression or \"no evidence\" in impression\n",
    "    sample_buckets[\"normal\" if is_normal else \"abnormal\"].append(item)\n",
    "\n",
    "print(f\"Original counts - Normal: {len(sample_buckets['normal'])}, Abnormal: {len(sample_buckets['abnormal'])}\")\n",
    "\n",
    "\n",
    "ABNORMAL_OVERSAMPLE_FACTOR = 3 \n",
    "ENHANCED_PROMPT_TEMPLATES = [\n",
    "    \"GIVEN THESE FINDINGS: {findings}\\n{original_instruction}\",\n",
    "    \"THE RADIOLOGIST NOTED: {findings}\\nBASED ON THIS, {original_instruction}\",\n",
    "    \"CLINICAL CONTEXT: {findings}\\nPLEASE PROVIDE YOUR ANALYSIS: {original_instruction}\",\n",
    "    \"{original_instruction}\\nRELEVANT FINDINGS INCLUDE: {findings}\"\n",
    "]\n",
    "REASONING_PROMPTS = [\n",
    "    \"<image> ANALYZE THE DUAL-VIEW CHEST RADIOGRAPHS AND DESCRIBE THE MOST CLINICALLY SIGNIFICANT FINDINGS.\",\n",
    "    \"<image> IDENTIFY AND PRIORITIZE THE TOP 3 RADIOGRAPHIC ABNORMALITIES THAT REQUIRE CLINICAL ATTENTION.\",\n",
    "    \"<image> COMPARE THE CURRENT STUDY WITH PRIOR IMAGING (IF AVAILABLE). WHAT INTERVAL CHANGES ARE MOST CONCERNING?\",\n",
    "    \"<image> WHAT RADIOGRAPHIC SIGNS SUGGEST DECOMPENSATION IN THIS PATIENT'S CONDITION?\",\n",
    "    \"<image> WHICH FINDINGS WOULD YOU IMMEDIATELY REPORT TO THE TREATING PHYSICIAN AND WHY?\",\n",
    "    \"<image> ASSESS THE POSITIONING AND PLACEMENT OF ALL TUBES, LINES, AND DEVICES.\",\n",
    "    \"<image> DESCRIBE ANY FINDINGS THAT SUGGEST ACUTE VERSUS CHRONIC PATHOLOGICAL PROCESSES.\",\n",
    "    \"<image> WHAT DIFFERENTIAL DIAGNOSES WOULD YOU CONSIDER BASED ON THESE RADIOGRAPHIC FINDINGS?\",\n",
    "    \"<image> EVALUATE THE CARDIOPULMONARY STATUS AND COMMENT ON ANY DECOMPENSATION SIGNS.\",\n",
    "    \"<image> IDENTIFY ANY FINDINGS THAT MAY REQUIRE IMMEDIATE INTERVENTION VERSUS FOLLOW-UP MONITORING.\"\n",
    "]\n",
    "\n",
    "\n",
    "converted = []\n",
    "\n",
    "def build_enhanced_prompt(item):\n",
    "    \"\"\"Generate multiple prompt variations incorporating findings\"\"\"\n",
    "    original_instruction = random.choice(REASONING_PROMPTS)\n",
    "    findings = item.get(\"findings\", \"\").strip()\n",
    "    \n",
    "    if not findings:\n",
    "        return [original_instruction]\n",
    "    \n",
    "    return [\n",
    "        template.format(\n",
    "            findings=findings,\n",
    "            original_instruction=original_instruction\n",
    "        )\n",
    "        for template in ENHANCED_PROMPT_TEMPLATES\n",
    "    ]\n",
    "\n",
    "\n",
    "for item in sample_buckets[\"normal\"]:\n",
    "    try:\n",
    "        enhanced_prompts = build_enhanced_prompt(item)\n",
    "        converted.append({\n",
    "            \"frontal\": item[\"frontal\"],\n",
    "            \"lateral\": item[\"lateral\"],\n",
    "            \"conversations\": [\n",
    "                {\"from\": \"human\", \"value\": enhanced_prompts[0]},\n",
    "                {\"from\": \"gpt\", \"value\": item[\"impression\"]}\n",
    "            ],\n",
    "            \"category\": \"normal\"\n",
    "        })\n",
    "    except KeyError as e:\n",
    "        print(f\"[Skip] Missing key {e} in normal sample\")\n",
    "\n",
    "\n",
    "for item in sample_buckets[\"abnormal\"]:\n",
    "    try:\n",
    "\n",
    "        enhanced_prompts = build_enhanced_prompt(item)\n",
    "        converted.append({\n",
    "            \"frontal\": item[\"frontal\"],\n",
    "            \"lateral\": item[\"lateral\"],\n",
    "            \"conversations\": [\n",
    "                {\"from\": \"human\", \"value\": enhanced_prompts[0] },\n",
    "                {\"from\": \"gpt\", \"value\": item[\"impression\"]}\n",
    "            ],\n",
    "            \"category\": \"abnormal_original\"\n",
    "        })\n",
    "        \n",
    "\n",
    "        for i, prompt in enumerate(enhanced_prompts[:ABNORMAL_OVERSAMPLE_FACTOR]):\n",
    "            converted.append({\n",
    "                \"frontal\": item[\"frontal\"],\n",
    "                \"lateral\": item[\"lateral\"],\n",
    "                \"conversations\": [\n",
    "                    {\"from\": \"human\", \"value\": prompt},\n",
    "                    {\"from\": \"gpt\", \"value\": item[\"impression\"]}\n",
    "                ],\n",
    "                \"category\": f\"abnormal_enhanced_{i+1}\"\n",
    "            })\n",
    "            \n",
    "    except KeyError as e:\n",
    "        print(f\"[Skip] Missing key {e} in abnormal sample\")\n",
    "\n",
    "\n",
    "random.shuffle(converted)\n",
    "\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump(converted, f, indent=2)\n",
    "\n",
    "\n",
    "category_counts = defaultdict(int)\n",
    "for item in converted:\n",
    "    category_counts[item[\"category\"]] += 1\n",
    "\n",
    "print(\"\\nFinal Dataset Composition:\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"- {category}: {count} samples\")\n",
    "print(f\"\\nSaved {len(converted)} samples to {output_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec17ad6",
   "metadata": {},
   "source": [
    "#### Generate Train Json For Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa46ef-2fb3-4e21-8f5f-bcf944bd8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "input_json = \"slava_llava_split_train.json\"\n",
    "output_json = \"slava_llava_report.json\"\n",
    "\n",
    "with open(input_json, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "sample_buckets = defaultdict(list)\n",
    "for item in data:\n",
    "    impression = item.get(\"impression\", \"\").lower()\n",
    "    is_normal = \"no acute\" in impression or \"normal\" in impression or \"no evidence\" in impression\n",
    "    sample_buckets[\"normal\" if is_normal else \"abnormal\"].append(item)\n",
    "\n",
    "print(f\"Original counts - Normal: {len(sample_buckets['normal'])}, Abnormal: {len(sample_buckets['abnormal'])}\")\n",
    "\n",
    "\n",
    "ABNORMAL_OVERSAMPLE_FACTOR = 4  # 3x more abnormal cases\n",
    "REPORT_INSTRUCTIONS = [\n",
    "    \"<image> Describe the findings in these frontal and lateral chest X-rays in a structured radiology report format.\",\n",
    "    \"<image> Generate a complete radiology report for these CXRs including findings and impression.\",\n",
    "    \"<image> Interpret these chest X-rays and provide a professional radiology report.\",\n",
    "    \"<image> What abnormalities are visible in these CXRs? Provide a structured report.\",\n",
    "    \"<image> Analyze these frontal and lateral chest X-rays and summarize the key findings.\",\n",
    "    \"<image> Prepare a radiology report for these images with findings and clinical impression.\",\n",
    "    \"<image> Evaluate these CXRs and document your observations in standard report format.\",\n",
    "    \"<image> Provide a detailed interpretation of these chest X-rays with findings and conclusion.\",\n",
    "    \"<image> Write a radiology report for these images following clinical documentation standards.\",\n",
    "    \"<image> Identify and describe any pathological findings in these CXRs in report format.\"\n",
    "]\n",
    "\n",
    "\n",
    "converted = []\n",
    "\n",
    "\n",
    "for item in sample_buckets[\"normal\"]:\n",
    "    try:\n",
    "        base_instruction = random.choice(REPORT_INSTRUCTIONS)\n",
    "        findings = item[\"findings\"]\n",
    "        impression = item[\"impression\"] \n",
    "        report_text = f\"FINDINGS: {findings}\"\n",
    "        report_text += f\"IMPRESSION: {impression}\"\n",
    "        converted.append({\n",
    "            \"frontal\": item[\"frontal\"],\n",
    "            \"lateral\": item[\"lateral\"],\n",
    "            \"conversations\": [\n",
    "                {\"from\": \"human\", \"value\": base_instruction},\n",
    "                {\"from\": \"gpt\", \"value\":report_text}\n",
    "            ],\n",
    "            \"category\": \"normal\"\n",
    "        })\n",
    "    except KeyError as e:\n",
    "        print(f\"[Skip] Missing key {e} in normal sample\")\n",
    "\n",
    "\n",
    "for item in sample_buckets[\"abnormal\"]:\n",
    "    try:\n",
    "\n",
    "        findings = item[\"findings\"]\n",
    "        impression = item[\"impression\"] \n",
    "        report_text = f\"FINDINGS: {findings}\"\n",
    "        report_text += f\"IMPRESSION: {impression}\"\n",
    "        converted.append({\n",
    "            \"frontal\": item[\"frontal\"],\n",
    "            \"lateral\": item[\"lateral\"],\n",
    "            \"conversations\": [\n",
    "                {\"from\": \"human\", \"value\": random.choice(REPORT_INSTRUCTIONS) },\n",
    "                {\"from\": \"gpt\", \"value\":report_text}\n",
    "            ],\n",
    "            \"category\": \"abnormal_original\"\n",
    "        })\n",
    "        \n",
    "   \n",
    "        for i in range(ABNORMAL_OVERSAMPLE_FACTOR):\n",
    "            converted.append({\n",
    "                \"frontal\": item[\"frontal\"],\n",
    "                \"lateral\": item[\"lateral\"],\n",
    "                \"conversations\": [\n",
    "                    {\"from\": \"human\", \"value\": random.choice(REPORT_INSTRUCTIONS)},\n",
    "                    {\"from\": \"gpt\", \"value\": report_text}\n",
    "                ],\n",
    "                \"category\": f\"abnormal_enhanced_{i+1}\"\n",
    "            })\n",
    "            \n",
    "    except KeyError as e:\n",
    "        print(f\"[Skip] Missing key {e} in abnormal sample\")\n",
    "\n",
    "random.shuffle(converted)\n",
    "\n",
    "\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump(converted, f, indent=2)\n",
    "\n",
    "\n",
    "category_counts = defaultdict(int)\n",
    "for item in converted:\n",
    "    category_counts[item[\"category\"]] += 1\n",
    "\n",
    "print(\"\\nFinal Dataset Composition:\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"- {category}: {count} samples\")\n",
    "print(f\"\\n Saved {len(converted)} samples to {output_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
