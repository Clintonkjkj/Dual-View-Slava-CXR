{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da48bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\clint\\\\miniconda3\\\\Lib\\\\site-packages\\\\spacy\\\\lang\\\\fa\\\\punctuation.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting radgraph\n",
      "  Using cached radgraph-0.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in c:\\users\\clint\\miniconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (2.7.1)\n",
      "Requirement already satisfied: transformers>=4.23.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (4.52.4)\n",
      "Requirement already satisfied: appdirs in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (1.4.4)\n",
      "Requirement already satisfied: jsonpickle in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (4.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (3.18.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (3.14.0)\n",
      "Collecting spacy (from radgraph)\n",
      "  Using cached spacy-3.8.7-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (3.9.1)\n",
      "Requirement already satisfied: dotmap in c:\\users\\clint\\miniconda3\\lib\\site-packages (from radgraph) (1.3.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\clint\\miniconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from torch>=1.8.1->radgraph) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from torch>=1.8.1->radgraph) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\clint\\miniconda3\\lib\\site-packages (from torch>=1.8.1->radgraph) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from torch>=1.8.1->radgraph) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\clint\\miniconda3\\lib\\site-packages (from torch>=1.8.1->radgraph) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\clint\\miniconda3\\lib\\site-packages (from torch>=1.8.1->radgraph) (78.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from transformers>=4.23.1->radgraph) (0.5.3)\n",
      "Requirement already satisfied: click in c:\\users\\clint\\miniconda3\\lib\\site-packages (from nltk->radgraph) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\clint\\miniconda3\\lib\\site-packages (from nltk->radgraph) (1.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (0.16.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (2.10.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from spacy->radgraph) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->radgraph) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->radgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->radgraph) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from requests->transformers>=4.23.1->radgraph) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from requests->transformers>=4.23.1->radgraph) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from requests->transformers>=4.23.1->radgraph) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from requests->transformers>=4.23.1->radgraph) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.1->radgraph) (1.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->radgraph) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->radgraph) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->radgraph) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->radgraph) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->radgraph) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->radgraph) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from jinja2->torch>=1.8.1->radgraph) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->radgraph) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->radgraph) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->radgraph) (2.19.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\clint\\miniconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->radgraph) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\clint\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->radgraph) (0.1.0)\n",
      "Using cached spacy-3.8.7-cp313-cp313-win_amd64.whl (13.9 MB)\n",
      "Installing collected packages: spacy, radgraph\n"
     ]
    }
   ],
   "source": [
    "!pip install radgraph tqdm pandas Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729cbf5",
   "metadata": {},
   "source": [
    "### Proccess Collected Images to Match Chest Xray Views also check the validity of collected studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ab4c3-626d-42e5-b88c-1b5f64788a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "MIMIC_FOLDER = 'MIMIC_Dataset'\n",
    "METADATA_CSV = 'mimic-cxr-2.0.0-metadata.csv'\n",
    "OUTPUT_FOLDER = 'Processed_MIMIC'\n",
    "BAD_FOLDER = 'invalid_studies1'\n",
    "\n",
    "FRONTAL_VIEWS = {'PA', 'AP', 'AP AXIAL', 'PA LLD', 'AP LLD', 'AP RLD', 'PA RLD', 'LPO', 'RAO', 'LAO'}\n",
    "LATERAL_VIEWS = {'LATERAL', 'LL', 'XTABLE LATERAL', 'SWIMMERS'}\n",
    "\n",
    "def map_view(view_str):\n",
    "    if pd.isna(view_str):\n",
    "        return None\n",
    "    view_str = view_str.strip().upper()\n",
    "    if view_str in FRONTAL_VIEWS:\n",
    "        return '0'\n",
    "    elif view_str in LATERAL_VIEWS:\n",
    "        return '1'\n",
    "    return None\n",
    "\n",
    "def infer_view_from_filename(filename):\n",
    "    for view in FRONTAL_VIEWS:\n",
    "        if view in filename.upper():\n",
    "            return '0'\n",
    "    for view in LATERAL_VIEWS:\n",
    "        if view in filename.upper():\n",
    "            return '1'\n",
    "    return None\n",
    "\n",
    "\n",
    "metadata = pd.read_csv(METADATA_CSV)\n",
    "metadata['view_label'] = metadata['ViewPosition'].apply(map_view)\n",
    "metadata.dropna(subset=['view_label'], inplace=True)\n",
    "\n",
    "\n",
    "study_to_dicom = {}\n",
    "for _, row in metadata.iterrows():\n",
    "    study_id = str(row['study_id'])\n",
    "    if study_id not in study_to_dicom:\n",
    "        study_to_dicom[study_id] = []\n",
    "    study_to_dicom[study_id].append((row['dicom_id'], row['view_label']))\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(BAD_FOLDER, exist_ok=True)\n",
    "\n",
    "for subject_id in os.listdir(MIMIC_FOLDER):\n",
    "    subject_path = os.path.join(MIMIC_FOLDER, subject_id)\n",
    "    if not os.path.isdir(subject_path):\n",
    "        continue\n",
    "\n",
    "    study_view_map = {}\n",
    "\n",
    "    for file_name in os.listdir(subject_path):\n",
    "        if not file_name.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(subject_path, file_name)\n",
    "\n",
    "     \n",
    "        matched_study = None\n",
    "        matched_label = None\n",
    "        for study_id, dicom_entries in study_to_dicom.items():\n",
    "            for dicom_id, label in dicom_entries:\n",
    "                if dicom_id in file_name:\n",
    "                    matched_study = study_id\n",
    "                    matched_label = label\n",
    "                    break\n",
    "            if matched_study:\n",
    "                break\n",
    "\n",
    "        if matched_study:\n",
    "            if matched_study not in study_view_map:\n",
    "                study_view_map[matched_study] = {'0': None, '1': None}\n",
    "            if matched_label in study_view_map[matched_study] and study_view_map[matched_study][matched_label] is None:\n",
    "                study_view_map[matched_study][matched_label] = (image_path, matched_label)\n",
    "            continue\n",
    "\n",
    "      \n",
    "        inferred_label = infer_view_from_filename(file_name)\n",
    "        if inferred_label is not None:\n",
    "            out_study_path = os.path.join(OUTPUT_FOLDER, subject_id)\n",
    "            os.makedirs(out_study_path, exist_ok=True)\n",
    "            dst = os.path.join(out_study_path, f\"{inferred_label}.jpeg\")\n",
    "            try:\n",
    "                shutil.copy(image_path, dst)\n",
    "              \n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {image_path} → {dst}: {e}\")\n",
    "            continue\n",
    "\n",
    "     \n",
    "        bad_path = os.path.join(BAD_FOLDER, subject_id)\n",
    "        os.makedirs(bad_path, exist_ok=True)\n",
    "        shutil.copy(image_path, os.path.join(bad_path, file_name))\n",
    "       \n",
    "\n",
    "  \n",
    "    for study_id, view_dict in study_view_map.items():\n",
    "        if not view_dict['0'] or not view_dict['1']:\n",
    "            bad_path = os.path.join(BAD_FOLDER, subject_id)\n",
    "            os.makedirs(bad_path, exist_ok=True)\n",
    "            for v in view_dict.values():\n",
    "                if v:\n",
    "                    shutil.copy(v[0], os.path.join(bad_path, os.path.basename(v[0])))\n",
    "           \n",
    "            continue\n",
    "\n",
    "        out_study_path = os.path.join(OUTPUT_FOLDER, subject_id)\n",
    "        os.makedirs(out_study_path, exist_ok=True)\n",
    "        for original_file, label in view_dict.values():\n",
    "            dst = os.path.join(out_study_path, f\"{label}.jpeg\")\n",
    "            try:\n",
    "                shutil.copy(original_file, dst)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {original_file} → {dst}: {e}\")\n",
    "print(\"Processing Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdf84f",
   "metadata": {},
   "source": [
    "#### Extract Valid Study Ids from Processed Images Folder (For Cleaning the text Using Radgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c78ded-0c9b-424f-a9fc-c128f800bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 34122 valid study IDs to valid_study_ids.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"Processed_MIMIC\")\n",
    "\n",
    "valid_study_ids = []\n",
    "\n",
    "for study_folder in base_dir.iterdir():\n",
    "    if study_folder.is_dir():\n",
    "        image0 = study_folder / \"0.jpeg\"\n",
    "        image1 = study_folder / \"1.jpeg\"\n",
    "        \n",
    "        if image0.exists() and image1.exists():\n",
    "            valid_study_ids.append(study_folder.name)\n",
    "       \n",
    "\n",
    "df = pd.DataFrame(valid_study_ids, columns=[\"study_id\"])\n",
    "df.to_csv(\"study_ids.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {len(valid_study_ids)} valid study IDs to valid_study_ids.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20f750",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e44f33-acde-471a-9021-c701668bd8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<csv.DictReader object at 0x000001C6D5415090>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting reports: 100%|████████████████████████████████████████████████████| 227835/227835 [00:48<00:00, 4704.90it/s]\n",
      "Processing study folders: 100%|██████████████████████████████████████████████████| 34122/34122 [15:05<00:00, 37.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "\n",
    "ZIP_PATH = 'mimic-cxr-reports.zip'\n",
    "IMAGE_ROOT = 'study_ids.csv'\n",
    "OUTPUT_JSON = \"radgraph_processed_output.json\"\n",
    "valid_id_path= \"valid_pa_lateral_studies.csv\"\n",
    "\n",
    "def load_valid_ids(csv_path):\n",
    "    valid_ids = set()\n",
    "    with open(csv_path, newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        print(reader)\n",
    "        for row in reader:\n",
    "            subject_id = row[\"subject_id\"].strip()\n",
    "            study_id = row[\"study_id\"].strip()\n",
    "            valid_ids.add((subject_id, study_id))\n",
    "    return valid_ids\n",
    "\n",
    "\n",
    "def extract_reports(zip_path):\n",
    "    reports = {}\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        txt_files = [f for f in zip_ref.namelist() if f.endswith('.txt')]\n",
    "        for file_path in tqdm(txt_files, desc=\"Extracting reports\"):\n",
    "            try:\n",
    "                parts = file_path.split('/')\n",
    "                if len(parts) >= 4 and parts[-1].startswith('s'):\n",
    "                    with zip_ref.open(file_path) as f:\n",
    "                        content = f.read().decode('utf-8')\n",
    "                        subject_id = parts[-2][1:] \n",
    "                        study_id = parts[-1][1:-4]  \n",
    "                        reports[(subject_id, study_id)] = content\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "    return reports\n",
    "\n",
    "\n",
    "def extract_findings_impression(text):\n",
    "    text = text.upper()\n",
    "    findings_match = re.search(\n",
    "        r\"(FINDINGS|OBSERVATION|DESCRIPTION):\\s*(.*?)(IMPRESSION|CONCLUSION|DIAGNOSIS|$)\",\n",
    "        text,\n",
    "        re.DOTALL| re.IGNORECASE\n",
    "    )\n",
    "    impression_match = re.search(\n",
    "        r\"(IMPRESSION|CONCLUSION|DIAGNOSIS):\\s*(.*)\",\n",
    "        text,\n",
    "        re.DOTALL| re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    findings = findings_match.group(2).strip() if findings_match else \"\"\n",
    "    impression = impression_match.group(2).strip() if impression_match else \"\"\n",
    "    return findings, impression\n",
    "\n",
    "\n",
    "def process_reports(zip_path, valid_ids_path, image_root, output_json):\n",
    "    valid_ids = load_valid_ids(valid_ids_path)\n",
    "    reports = extract_reports(zip_path)\n",
    "    result = {}\n",
    "\n",
    "\n",
    "    study_pd = pd.read_csv(image_root)\n",
    "    study_dirs = study_pd['study_id'].tolist()\n",
    "\n",
    "    for study_id in tqdm(study_dirs, desc=\"Processing study folders\"):\n",
    "\n",
    "        subject_id = next((sid for sid, sidy in valid_ids if int(sidy) == study_id), None)\n",
    "        if subject_id is None:\n",
    "            continue\n",
    "        report_text = reports.get((subject_id, str(study_id)))\n",
    "        if report_text is None:\n",
    "            continue\n",
    "\n",
    "        findings, impression = extract_findings_impression(report_text)\n",
    "        if not findings or not impression:\n",
    "            continue\n",
    "\n",
    "        base_prefix = \"Processed_MIMIC\"\n",
    "        image_paths = [str(study_id)+\"/0.jpeg\", str(study_id)+\"/1.jpeg\"]\n",
    "        result[study_id] = {\n",
    "            \"subject_id\": subject_id,\n",
    "            \"findings\": findings.replace(\"\\n\", \" \").strip(),\n",
    "            \"impression\": impression.replace(\"\\n\", \" \").strip(),\n",
    "            \"image_paths\": image_paths\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\n",
    "result = process_reports(ZIP_PATH,  valid_id_path,IMAGE_ROOT,OUTPUT_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c11de8-ea7c-4b43-b4aa-85565c1257ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_JSON_drive = \"radgraph_processed_output.json\"\n",
    "with open(OUTPUT_JSON_drive, \"w\") as f:\n",
    "        json.dump(result, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312e8a8",
   "metadata": {},
   "source": [
    "#### Resize center Crop Imges  to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b740948-876b-4efd-8df5-b71c65efd475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing studies: 100%|██████████████████████████████████████████████████████| 32734/32734 [9:09:13<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "json_path = \"radgraph_processed_output.json\" \n",
    "base_prefix = \"Processed_MIMIC\"          \n",
    "save_prefix = \"MIMIC_Dataset336_stretched\"  \n",
    "output_size = 336                         \n",
    "\n",
    "os.makedirs(save_prefix, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "def crop_and_stretch(img, final_size=336):\n",
    "    \"\"\"\n",
    "    Crop black borders and stretch to final_size x final_size.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "\n",
    "    if coords is None:\n",
    "        return cv2.resize(img, (final_size, final_size))  \n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    stretched = cv2.resize(cropped, (final_size, final_size), interpolation=cv2.INTER_LANCZOS4)\n",
    "    return stretched\n",
    "\n",
    "def resize_image(input_path, output_path, size=336):\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Failed to load image: {input_path}\")\n",
    "\n",
    "    processed = crop_and_stretch(img, final_size=size)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    cv2.imwrite(output_path, processed)\n",
    "\n",
    "\n",
    "\n",
    "def resize_images_from_json(json_path, base_prefix, save_prefix, size=336):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for study_id, info in tqdm(data.items(), desc=\"Processing studies\"):\n",
    "        image_paths = info.get(\"image_paths\", [])\n",
    "        if len(image_paths) != 2:\n",
    "            continue  # Skip non-dual-view entries\n",
    "\n",
    "        for rel_path in image_paths:\n",
    "            rel_path = rel_path.strip(\"/\")\n",
    "            full_input = os.path.join(base_prefix, rel_path)\n",
    "            full_output = os.path.join(save_prefix, rel_path)\n",
    "\n",
    "            try:\n",
    "                resize_image(full_input, full_output, size=size)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {full_input}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resize_images_from_json(json_path, base_prefix, save_prefix, size=output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cce279-3318-4f2c-b005-f293b4399723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing studies: 100%|██████████████████████████████████████████████████████| 32734/32734 [8:02:43<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------\n",
    "# CONFIG\n",
    "# ----------------------\n",
    "json_path = \"radgraph_processed_output.json\" \n",
    "base_prefix = \"Processed_MIMIC\"          \n",
    "save_prefix = \"MIMIC_Dataset224_clean\"  \n",
    "output_size = 224                      \n",
    "\n",
    "os.makedirs(save_prefix, exist_ok=True)\n",
    "\n",
    "\n",
    "def crop_and_resize_with_padding(img, final_size=224):\n",
    "    \"\"\"\n",
    "    Remove black borders and resize to square with padding (no stretching).\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "\n",
    "    if coords is None:\n",
    "        return cv2.resize(img, (final_size, final_size))\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "    h, w = cropped.shape[:2]\n",
    "    scale = final_size / max(h, w)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(cropped, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    top_pad = (final_size - new_h) // 2\n",
    "    bottom_pad = final_size - new_h - top_pad\n",
    "    left_pad = (final_size - new_w) // 2\n",
    "    right_pad = final_size - new_w - left_pad\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top_pad, bottom_pad, left_pad, right_pad,\n",
    "                                borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    return padded\n",
    "\n",
    "\n",
    "def resize_image(input_path, output_path, size=224):\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Failed to load image: {input_path}\")\n",
    "\n",
    "    processed = crop_and_resize_with_padding(img, final_size=size)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    cv2.imwrite(output_path, processed)\n",
    "\n",
    "def resize_images_from_json(json_path, base_prefix, save_prefix, size=224):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for study_id, info in tqdm(data.items(), desc=\"Processing studies\"):\n",
    "        image_paths = info.get(\"image_paths\", [])\n",
    "        if len(image_paths) != 2:\n",
    "            continue  # Skip non-dual-view entries\n",
    "\n",
    "        for rel_path in image_paths:\n",
    "            rel_path = rel_path.strip(\"/\")\n",
    "            full_input = os.path.join(base_prefix, rel_path)\n",
    "            full_output = os.path.join(save_prefix, rel_path)\n",
    "\n",
    "            try:\n",
    "                resize_image(full_input, full_output, size=size)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {full_input}: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resize_images_from_json(json_path, base_prefix, save_prefix, size=output_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
